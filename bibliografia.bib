%%
%% Arquivo de referências bibliográficas.
%%

@article{lagaris-etal:98,
	author={Lagaris, I. E. and Likas, A. and Fotiadis, D. I.},
	journal={IEEE Transactions on Neural Networks},
	title={Artificial neural networks for solving ordinary and partial differential equations},
	year={1998},
	volume={9},
	number={5},
	pages={987-1000},
	doi={10.1109/72.712178},
	ISSN={1045-9227},
	month={Sep.}
}

@article{lu-etal:21-deepxde,
   title={DeepXDE: A Deep Learning Library for Solving Differential Equations},
   volume={63},
   ISSN={1095-7200},
   url={http://dx.doi.org/10.1137/19M1274067},
   DOI={10.1137/19m1274067},
   number={1},
   journal={SIAM Review},
   publisher={Society for Industrial \& Applied Mathematics (SIAM)},
   author={Lu Lu and Xuhui Meng and Zhiping Mao and George Em Karniadakis},
   year={2021},
   month=jan, pages={208–228} 
}

@article{psichogios-etal:92,
    author = {Psichogios, Dimitris C. and Ungar, Lyle H.},
    title = {A hybrid neural network-first principles approach to process modeling},
    journal = {AIChE Journal},
    volume = {38},
    number = {10},
    pages = {1499-1511},
    doi = {10.1002/aic.690381003},
    year = {1992}
}

@article{kingma-ba:14-adam,
    title     = {Adam: A Method for Stochastic Optimization},
    author    = {Kingma, Diederik P. and Ba, Jimmy},
    journal   = {International Conference on Learning Representations},
    year      = {2014}
}

@article{raissi-etal:19,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier},
  doi={10.1016/j.jcp.2018.10.045}
}

@article{liu-nocedal:89-lbfgs,
  author    = {Liu, D. C. and Nocedal, J.},
  title     = {On the limited memory {BFGS} method for large scale optimization},
  journal   = {Mathematical Programming},
  volume    = {45},
  pages     = {503--528},
  year      = {1989},
  doi       = {10.1007/BF01589116},
  url       = {https://doi.org/10.1007/BF01589116}
}

@article{cybenko:89,
  author    = {Cybenko, G.},
  title     = {Approximation by superpositions of a sigmoidal function},
  journal   = {Mathematics of Control, Signals, and Systems},
  volume    = {2},
  pages     = {303--314},
  year      = {1989},
  doi       = {10.1007/BF02551274},
  url       = {https://doi.org/10.1007/BF02551274}
}

@article{lee-kang:90,
	author={Lee, H. and Kand, I. S.},
	journal={Journal of Computational Physics},
	title={Neural algorithm for solving differential equations},
	year={1990},
	volume={91},
	number={1},
	pages={110-131},
	doi={10.1016/0021-9991(90)90007-N},
	ISSN={},
	month={},
}

@article{meade-fernandez:94,
  author = {Meade, A. J. and Fernandez, A. A.},
  title = {The numerical solution of linear ordinary differential equations by feedforward neural networks},
  journal = {Math. Comput. Model.},
  publisher = {Elsevier Science Publishers B. V.},
  volume = {19},
  number = {12},
  doi = {10.1016/0895-7177(94)90095-7},
  pages = {1–25},
  numpages = {25},
year = {1994}
}


@article{kermack-mcKendrick:1927,
	title={A contribution to the mathematical theory of epidemics},
	author={Kermack, W. O. and McKendrick, A. G.},
	journal={Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	volume={115},
	number={772},
	pages={700--721},
	year={1927},
	doi={10.1098/rspa.1927.0118}
}

@article{kermack-mcKendrick-pt2:1932,
	author = {Kermack, William Ogilvy  and McKendrick, A. G. },
	title = {Contributions to the mathematical theory of epidemics. II. —The problem of endemicity},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	volume = {138},
	number = {834},
	pages = {55-83},
	year = {1932},
	doi = {10.1098/rspa.1932.0171},
	URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1932.0171},
	eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1932.0171}
}

@article{kermack-mcKendrick-pt3:1933,
	author = {Kermack, William Ogilvy  and McKendrick, A. G. },
	title = {Contributions to the mathematical theory of epidemics. III.—Further studies of the problem of endemicity},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	volume = {141},
	number = {843},
	pages = {94-122},
	year = {1933},
	doi = {10.1098/rspa.1933.0106},
	URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1933.0106},
	eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1933.0106}
}

@inproceedings{rodriguez-etal:2022-einns,
  title={EINNs: Epidemiologically-Informed Neural Networks},
  author={Rodriguez, Alexander and Cui, Jiaming and Ramakrishnan, Naren and Adhikari, Bijaya and Prakash, B. Aditya},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  year={2023}
}


@ARTICLE{ouyoussef-etal:24-subcompartimentos,
	author = {Ouyoussef, Kawtar Idhammou and El Karkri, Jaafar and Tine, Léon Matar and Aboulaich, Rajae},
	title = {Physics-informed neural networks for parameter estimation and simulation of a two-group epidemiological model},
	year = {2024},
	journal = {International Journal of Modeling, Simulation, and Scientific Computing},
	volume = {15},
	number = {3},
	doi = {10.1142/S1793962324500429},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199247126&doi=10.1142%2fS1793962324500429&partnerID=40&md5=75c96ad2ee9d4ef94eb1f14d23b58425},
	abstract = {This paper provides a comprehensive exploration of physics-informed neural networks and their core features. It delves into their role in tackling inverse problems inherent in ordinary differential equation-based models. Within this context, we introduce a two-group epidemiological model, elucidating its fundamental attributes. The central objective of this research is to accurately estimate the model parameters for both groups in the epidemiological model. We offer a detailed exposition of the adopted methodology, providing insights into the algorithm and the techniques employed for its implementation. Through this analysis, we illuminate the complexities of our study, contributing to the growing body of knowledge in this field, which intersects epidemiology and neural network-based parameter estimation for an enriched understanding of infectious disease dynamics. © 2024 The Author(s).},
	author_keywords = {algorithm implementation; Epidemiological model; infectious disease dynamics; ordinary differential equations; parameters estimation; physics-informed neural networks},
	keywords = {Diseases; Inverse problems; Parameter estimation; Algorithm implementation; Core features; Disease dynamics; Epidemiological modeling; Infectious disease; Infectious disease dynamic; Neural-networks; Parameter simulations; Parameters estimation; Physic-informed neural network; Ordinary differential equations},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{arulandu-etal:23-vacinacao,
	author = {Arulandu, Alvan Caleb and Seshaiyer, Padmanabhan},
	title = {PHYSICS-INFORMED NEURAL NETWORKS FOR INFORMED VACCINE DISTRIBUTION IN META-POPULATIONS},
	year = {2023},
	journal = {Journal of Machine Learning for Modeling and Computing},
	volume = {4},
	number = {3},
	pages = {83 – 99},
	doi = {10.1615/JMachLearnModelComput.2023047642},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006553822&doi=10.1615%2fJMachLearnModelComput.2023047642&partnerID=40&md5=d04e4b230160aee713a7bc1571692a31},
	abstract = {Accurate numerical and physical models play an important role in modeling the spread of infectious disease as well as informing policy decisions. Vaccination programs rely on the estimation of disease parameters from limited, error-prone reported data. Using physics-informed neural networks (PINNs) as universal function approximators of the susceptible-infected-recovered (SIR) compartmentalized differential equation model, we create a data-driven framework that uses reported data to estimate disease spread and approximate corresponding disease parameters. We apply this to data from a London boarding school, demonstrating the framework’s ability to produce accurate disease and parameter estimations despite noisy data. However, real-world populations contain subpopulations, each exhibiting different levels of risk and activity. Thus, we expand our framework to model meta-populations of preferentially-mixed subgroups with various contact rates, introducing a new substitution to decrease the number of parameters. Optimal parameters are estimated through PINNs which are then used in a negative gradient approach to calculate an optimal vaccine distribution plan for informed policy decisions. We also manipulate a new hyperparameter in the loss function of the PINNs network to expedite training. Together, our work creates a data-driven tool for future infectious disease vaccination efforts in heterogeneously mixed populations. © 2023 by Begell House, Inc.},
	author_keywords = {compartmental models; heterogeneity; neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{nelson-etal:24-japao,
	author = {Nelson, S. Patrick and Raja, R. and Eswaran, P. and Alzabut, J. and Rajchakit, G.},
	title = {Modeling the dynamics of Covid-19 in Japan: employing data-driven deep learning approach},
	year = {2024},
	journal = {International Journal of Machine Learning and Cybernetics},
	doi = {10.1007/s13042-024-02301-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201409261&doi=10.1007%2fs13042-024-02301-5&partnerID=40&md5=fcc869d76810d112561a40fcb39068b8},
	abstract = {This paper aims to build the SVIHRD model for COVID-19 and it also simultaneously conduct stability and numerical analysis on the transmission of COVID-19. Here we do a mathematical analysis for the SVIHRD model, which involves positivity, boundedness, uniqueness, and proving both global and local stability. In the process of numerical simulation, we use real-world data for COVID-19 cases in Japan. An important feature presents in this paper, is that we replace the usual numerical solving technique for obtaining the parameters with a Physics Informed Neural Network (PINN). This PINN needs an order of time instances as input and the number of Susceptible (S), Vaccinated (V), Infected (I), Hospitalized (H), Recovered (R), and Death (D) people per time instances to learn specific parameters of the model using loss functions. We developed three different PINN setups-the baseline model, configuration-I, and configuration-II-to explore and optimize these parameters for modeling COVID-19 dynamics in Japan. During the validation process, we evaluated how well the learned parameters from these three PINN architectures predicted real infection data for the next two months. The baseline model, with four hidden layers and 32 neurons each, performed well with an R2 value of 0.8038 and a Wilcoxon signed-rank test p value of 0.001556, closely matching actual infection data. A sensitivity analysis of the baseline model’s parameters showed that the vaccination rate σ is the most sensitive. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	author_keywords = {Deep learning; Equilibrium point; Machine learning; Mathematical modeling; Physics informed neural network},
	keywords = {Deep neural networks; Multilayer neural networks; Numerical methods; Sensitivity analysis; Baseline models; Data driven; Deep learning; Equilibrium point; Learning approach; Machine-learning; Mathematical modeling; Neural-networks; Physic informed neural network; Time instances; COVID-19},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{ning-etal:22-euler,
	author = {Ning, Xiao and Li, Xi-An and Wei, Yongyue and Chen, Feng},
	title = {Euler iteration augmented physics-informed neural networks for time-varying parameter estimation of the epidemic compartmental model},
	year = {2022},
	journal = {Frontiers in Physics},
	volume = {10},
	doi = {10.3389/fphy.2022.1062554},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145384710&doi=10.3389%2ffphy.2022.1062554&partnerID=40&md5=969076b392135c96543d6926df5e406a},
	abstract = {Introduction: Differential equations governed compartmental models are known for their ability to simulate epidemiological dynamics and provide highly accurate descriptive and predictive results. However, identifying the corresponding parameters of flow from one compartment to another in these models remains a challenging task. These parameters change over time due to the effect of interventions, virus variation and so on, thus time-varying compartmental models are required to reflect the dynamics of the epidemic and provide plausible results. Methods: In this paper, we propose an Euler iteration augmented physics-informed neural networks(called Euler-PINNs) to optimally integrates real-world reported data, epidemic laws and deep neural networks to capture the dynamics of COVID-19. The proposed Euler-PINNs method integrates the differential equations into deep neural networks by discretizing the compartmental model with suitable time-step and expressing the desired parameters as neural networks. We then define a robust and concise loss of the predicted data and the observed data for the epidemic in question and try to minimize it. In addition, a novel activation function based on Fourier theory is introduced for the Euler-PINNs method, which can deal with the inherently stochastic and noisy real-world data, leading to enhanced model performance. Results and Discussion: Furthermore, we verify the effectiveness of the Euler-PINNs method on 2020 COVID-19-related data in Minnesota, the United States, both qualitative and quantitative analyses of the simulation results demonstrate its accuracy and efficiency. Finally, we also perform predictions based on data from the early stages of the outbreak, and the experimental results demonstrate that the Euler-PINNs method remains robust on small dataset. Copyright © 2022 Ning, Li, Wei and Chen.},
	author_keywords = {Euler iteration; fourier feature mapping; parameter estimation; physics-informed neural network; SIRD compartmental model},
	keywords = {COVID-19; Dynamics; Epidemiology; Iterative methods; Parameter estimation; Stochastic models; Stochastic systems; Time varying networks; Viruses; Compartmental modelling; Euler iteration; Feature mapping; Fourier feature mapping; Fourier features; Neural-networks; Parameters estimation; Physic-informed neural network; Real-world; SIRD compartmental model; Differential equations},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{han-etal:24-prim-artigo-alemanha,
	author = {Han, Shuai and Stelz, Lukas and Stoecker, Horst and Wang, Lingxiao and Zhou, Kai},
	title = {Approaching epidemiological dynamics of COVID-19 with physics-informed neural networks},
	year = {2024},
	journal = {Journal of the Franklin Institute},
	volume = {361},
	number = {6},
	doi = {10.1016/j.jfranklin.2024.106671},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186494686&doi=10.1016%2fj.jfranklin.2024.106671&partnerID=40&md5=c6f62df7ebafa637a85e89ac5ee26f45},
	abstract = {A physics-informed neural network (PINN) embedded with the susceptible–infected–removed (SIR) model is devised to understand the temporal evolution dynamics of infectious diseases. Firstly, the effectiveness of this approach is demonstrated on synthetic data as generated from the numerical solution of the susceptible–asymptomatic–infected–recovered–dead (SAIRD) model. Then, the method is applied to COVID-19 data reported for Germany and shows that it can accurately identify and predict virus spread trends. The results indicate that an incomplete physics-informed model can approach more complicated dynamics efficiently. Thus, the present work demonstrates the high potential of using machine learning methods, e.g., PINNs, to study and predict epidemic dynamics in combination with compartmental models. © 2024 The Franklin Institute},
	author_keywords = {COVID-19; Epidemiological dynamics; Physics-informed machine learning},
	keywords = {Dynamics; Machine learning; Viruses; Epidemiological dynamic; Infectious disease; Machine-learning; Neural-networks; Numerical solution; Physic-informed machine learning; Suscep-tible-infected-removed models; Synthetic data; Temporal evolution; Virus spreads; COVID-19},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access}
}

@ARTICLE{long-etal:21-L2,
	author = {Long, Jie and Khaliq, A.Q.M. and Furati, K.M.},
	title = {Identification and prediction of time-varying parameters of COVID-19 model: a data-driven deep learning approach},
	year = {2021},
	journal = {International Journal of Computer Mathematics},
	volume = {98},
	number = {8},
	pages = {1617 – 1632},
	doi = {10.1080/00207160.2021.1929942},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106627387&doi=10.1080%2f00207160.2021.1929942&partnerID=40&md5=803b3e59fc4241f274b002aae280c6ef},
	abstract = {Data-driven deep learning provides efficient algorithms for parameter identification of epidemiology models. Unlike the constant parameters, the complexity of identifying time-varying parameters is largely increased. In this paper, a variant of physics-informed neural network is adopted to identify the time-varying parameters of the Susceptible-Infectious-Recovered-Deceased model for the spread of COVID-19 by fitting daily reported cases. The learned parameters are verified by utilizing an ordinary differential equation solver to compute the corresponding solutions of this compartmental model. The effective reproduction number based on these parameters is calculated. Long Short-Term Memory neural network is employed to predict the future weekly time-varying parameters. The numerical simulations demonstrate that PINN combined with LSTM yields accurate and effective results. © 2021 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {COVID-19; deep neural network; LSTM; PINN; SIRD},
	keywords = {Cell proliferation; Learning systems; Long short-term memory; Ordinary differential equations; Parameter estimation; Time varying control systems; Time varying networks; Compartmental model; Constant parameters; Corresponding solutions; Data driven; Learning approach; Ordinary differential equation solver; Reproduction numbers; Time varying parameter; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Green Open Access}
}

@article{heldmann-etal:23-biobjective-opt,
  title = {PINN training using biobjective optimization: The trade-off between data loss and residual loss},
  journal = {Journal of Computational Physics},
  volume = {488},
  pages = {112211},
  year = {2023},
  issn = {0021-9991},
  doi = {https://doi.org/10.1016/j.jcp.2023.112211},
  url = {https://www.sciencedirect.com/science/article/pii/S0021999123003066},
  author = {Fabian Heldmann and Sarah Berkhahn and Matthias Ehrhardt and Kathrin Klamroth},
  keywords = {Physics-informed neural networks, Compartment models, Loss function, Multiobjective optimization, Weighting parameters, Pareto front},
  abstract = {Physics informed neural networks (PINNs) have proven to be an efficient tool to represent problems for which measured data are available and for which the dynamics in the data are expected to follow some physical laws. In this paper, we suggest a multiobjective perspective on the training of PINNs by treating the data loss and the residual loss as two individual objective functions in a truly biobjective optimization approach. As a showcase example, we consider COVID-19 predictions in Germany and built an extended susceptibles-infected-recovered (SIR) model with additionally considered leaky-vaccinated and hospitalized populations (SVIHR model) to model the transition rates and to predict future infections. SIR-type models are expressed by systems of ordinary differential equations (ODEs). We investigate the suitability of the generated PINN for COVID-19 predictions and compare the resulting predicted curves with those obtained by applying the method of non-standard finite differences to the system of ODEs and initial data. The approach is applicable to various systems of ODEs that define dynamical regimes. Those regimes do not need to be SIR-type models, and the corresponding underlying data sets do not have to be associated with COVID-19.}
}

@ARTICLE{shamsara-etal:25-omicron,
	author = {Shamsara, Elham and König, Florian and Pfeifer, Nico},
	title = {An informed deep learning model of the Omicron wave and the impact of vaccination},
	year = {2025},
	journal = {Computers in Biology and Medicine},
	volume = {191},
	doi = {10.1016/j.compbiomed.2025.109968},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002151013&doi=10.1016%2fj.compbiomed.2025.109968&partnerID=40&md5=b1244c15295694df7ec626c4394d6c0d},
	abstract = {The Omicron (B.1.1.529) variant of SARS-CoV-2 emerged in November 2021 and has since evolved into multiple lineages. Understanding its transmission, vaccine efficacy, and potential for reinfection is crucial. This study examines the dynamics of Omicron in Germany, France, and Italy by employing Physics-Informed Neural Networks to estimate the temporal parameters influencing its spread. We validated the performance of our model using the Root Mean Squared Percent Error (RMSPE). Our analysis revealed significant correlations between specific viral mutations—S371F, T376A, D405N, and R408S—and increased transmission rates in all three countries. These mutations, prevalent in the Omicron BA.2 and BA.3 sublineages, are linked to immune evasion and heightened transmissibility. © 2025 The Author(s)},
	author_keywords = {Compartmental models; COVID-19; Granger Causality Test; PINNs},
	keywords = {COVID-19; COVID-19 Vaccines; Deep Learning; France; Germany; Humans; Italy; Mutation; SARS-CoV-2; SARS-CoV-2 variants; Vaccination; Deep reinforcement learning; Macroinvertebrates; Mean square error; SARS-CoV-2 vaccine; SARS-CoV-2 vaccine; Compartmental modelling; Granger causality test; Learning models; Neural-networks; Performance; PINN; Re-infection; Root-mean-squared; Transmission rates; Vaccine efficacies; Article; compartment model; coronavirus disease 2019; death; deep learning; drug efficacy; feed forward neural network; France; Germany; health status; hospitalization; human; immune evasion; information processing; informed neural network; Italy; mutation; nonhuman; physics; quantitative analysis; reinfection; root mean squared error; SARS-CoV-2 Omicron; vaccination; viral evolution; virus transmission; coronavirus disease 2019; epidemiology; genetics; immunology; prevention and control; Severe acute respiratory syndrome coronavirus 2; vaccination; virology; COVID-19},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{nguyen-etal:22-raissi-seirp,
	author = {Nguyen, Long and Raissi, Maziar and Seshaiyer, Padmanabhan},
	title = {Modeling, Analysis and Physics Informed Neural Network approaches for studying the dynamics of COVID-19 involving human-human and human-pathogen interaction},
	year = {2022},
	journal = {Computational and Mathematical Biophysics},
	volume = {10},
	number = {1},
	pages = {1 – 17},
	doi = {10.1515/cmb-2022-0001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125789439&doi=10.1515%2fcmb-2022-0001&partnerID=40&md5=90f6956fb3cafbc7a76f6498f77fef89},
	abstract = {In this work, the dynamics of the spread of COVID-19 is considered in the presence of both human-to-human transmission as well as environment-to-human transmission. Specifically, we expand and modify traditional epidemiological model for COVID-19 by incorporating a compartment to study the dynamics of pathogen concentration in the environmental reservoir, for instance concentration of droplets in closed spaces. We perform a mathematical analysis for the model proposed including an endemic equilibrium analysis as well as a next-generation approach both of which help to derive the basic reproduction number. We also study the efficacy of wearing a facemask through this model. Another important contribution of this work is the introduction to physics informed deep learning methods (PINNs) to study the dynamics. We propose this as an alternative to traditional numerical methods for solving system of differential equations used to describe dynamics of infectious diseases. Our results show that the proposed PINNs approach is a reliable candidate for both solving such systems and for helping identify important parameters that control the disease dynamics.  © 2022 Long Nguyen et al., published by De Gruyter.},
	author_keywords = {Compartmental Models; COVID-19 Model; Deep Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access}
}

@article{ghosh-etal:23-subnotificacao,
  author = {Ghosh, Samiran and Ogueda-Oliva, Alonso and Ghosh, Aditi and Banerjee, Malay and Padmanabhan, Seshaiyer},
  year = {2023},
  month = {11},
  pages = {},
  title = {Understanding the implications of under-reporting, vaccine efficiency and social behavior on the post-pandemic spread using physics informed neural networks: A case study of China},
  volume = {18},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0290368}
}

@ARTICLE{millevoi-etal:24-split-join-pinns,
	author = {Millevoi, Caterina and Pasetto, Damiano and Ferronato, Massimiliano},
	title = {A Physics-Informed Neural Network approach for compartmental epidemiological models},
	year = {2024},
	journal = {PLoS Computational Biology},
	volume = {20},
	number = {9},
	doi = {10.1371/journal.pcbi.1012387},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203432916&doi=10.1371%2fjournal.pcbi.1012387&partnerID=40&md5=5fc619838ca1b408adc707c6a90ac0a8},
	abstract = {Compartmental models provide simple and efficient tools to analyze the relevant transmission processes during an outbreak, to produce short-term forecasts or transmission scenarios, and to assess the impact of vaccination campaigns. However, their calibration is not straightforward, since many factors contribute to the rapid change of the transmission dynamics. For example, there might be changes in the individual awareness, the imposition of non-pharmacological interventions and the emergence of new variants. As a consequence, model parameters such as the transmission rate are doomed to vary in time, making their assessment more challenging. Here, we propose to use Physics-Informed Neural Networks (PINNs) to track the temporal changes in the model parameters and the state variables. PINNs recently gained attention in many engineering applications thanks to their ability to consider both the information from data (typically uncertain) and the governing equations of the system. The ability of PINNs to identify unknown model parameters makes them particularly suitable to solve ill-posed inverse problems, such as those arising in the application of epidemiological models. Here, we develop a reduced-split approach for the implementation of PINNs to estimate the temporal changes in the state variables and transmission rate of an epidemic based on the SIR model equation and infectious data. The main idea is to split the training first on the epidemiological data, and then on the residual of the system equations. The proposed method is applied to five synthetic test cases and two real scenarios reproducing the first months of the Italian COVID-19 pandemic. Our results show that the split implementation of PINNs outperforms the joint approach in terms of accuracy (up to one order of magnitude) and computational times (speed up of 20%). Finally, we illustrate that the proposed PINN-method can also be adopted to produced short-term forecasts of the dynamics of an epidemic. © 2024 Millevoi et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Algorithms; Computational Biology; Computer Simulation; COVID-19; Epidemics; Epidemiological Models; Humans; Neural Networks, Computer; SARS-CoV-2; COVID-19; Compartmental modelling; Consequence models; Epidemiological modeling; Modeling parameters; Neural-networks; Short-term forecasts; Simple++; Temporal change; Transmission dynamics; Transmission rates; Article; awareness; basic reproduction number; calibration; compartment model; coronavirus disease 2019; disease surveillance; disease transmission; dynamics; epidemic; epidemiological model; evolution; hospitalization; human; infection; nerve cell network; pandemic; physics; prediction; simulation; susceptible infected recovered model; vaccination; virus transmission; algorithm; artificial neural network; bioinformatics; computer simulation; coronavirus disease 2019; epidemiological model; epidemiology; prevention and control; procedures; Severe acute respiratory syndrome coronavirus 2; Inverse problems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{ogueda-oliva:23-colombia-duas-cidades,
	author = {Ogueda-Oliva, Alonso G. and Martínez-Salinas, Erika Johanna and Arunachalam, Viswanathan and Seshaiyer, Padmanabhan},
	title = {MACHINE LEARNING FOR PREDICTING THE DYNAMICS OF INFECTIOUS DISEASES DURING TRAVEL THROUGH PHYSICS INFORMED NEURAL NETWORKS},
	year = {2023},
	journal = {Journal of Machine Learning for Modeling and Computing},
	volume = {4},
	number = {3},
	pages = {17 – 35},
	doi = {10.1615/JMachLearnModelComput.2023047213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006554742&doi=10.1615%2fJMachLearnModelComput.2023047213&partnerID=40&md5=672b3d4fc327420a2609ab66cd4a62c2},
	abstract = {In the past few years, approaches such as physics informed neural networks (PINNs) have been applied to a variety of applications that can be modeled by linear and nonlinear ordinary and partial differential equations. Specifically, this work builds on the application of PINNs to a SIRD (suscep-tible, infectious, recovered, and dead) compartmental model and enhances it to build new mathematical models that incorporate transportation between populations and their impact on the dynamics of infectious diseases. Our work employs neural networks capable of learning how diseases spread, forecasting their progression, and finding their unique parameters. We show how these approaches are capable of predicting the behavior of a disease described by governing differential equations that include parameters and variables associated with the movement of the population between neigh-boring cities. We show that our model validates real data and also how such PINNs based methods predict optimal parameters for given datasets. © 2023 by Begell House, Inc.},
	author_keywords = {compartmental models; deep learning; epidemiology; neural networks; transport},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{bertaglia-etal:22-sir-reacao-difusao,
	author = {Bertaglia, Giulia and Lu, Chuan and Pareschi, Lorenzo and Zhu, Xueyu},
	title = {Asymptotic-Preserving Neural Networks for multiscale hyperbolic models of epidemic spread},
	year = {2022},
	journal = {Mathematical Models and Methods in Applied Sciences},
	volume = {32},
	number = {10},
	pages = {1949 – 1985},
	doi = {10.1142/S0218202522500452},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140742473&doi=10.1142%2fS0218202522500452&partnerID=40&md5=170623db80cb3dca5ce350b87afb42f1},
	abstract = {When investigating epidemic dynamics through differential models, the parameters needed to understand the phenomenon and to simulate forecast scenarios require a delicate calibration phase, often made even more challenging by the scarcity and uncertainty of the observed data reported by official sources. In this context, Physics-Informed Neural Networks (PINNs), by embedding the knowledge of the differential model that governs the physical phenomenon in the learning process, can effectively address the inverse and forward problem of data-driven learning and solving the corresponding epidemic problem. In many circumstances, however, the spatial propagation of an infectious disease is characterized by movements of individuals at different scales governed by multiscale partial differential equations. This reflects the heterogeneity of a region or territory in relation to the dynamics within cities and in neighboring zones. In presence of multiple scales, a direct application of PINNs generally leads to poor results due to the multiscale nature of the differential model in the loss function of the neural network. To allow the neural network to operate uniformly with respect to the small scales, it is desirable that the neural network satisfies an Asymptotic-Preservation (AP) property in the learning process. To this end, we consider a new class of AP neural networks for multiscale hyperbolic transport models of epidemic spread that, thanks to an appropriate AP formulation of the loss function, is capable of working uniformly at the different scales of the system. A series of numerical tests for different epidemic scenarios confirms the validity of the proposed approach, highlighting the importance of the AP property in the neural network when dealing with multiscale problems especially in presence of sparse and partially observed systems.  © 2022 World Scientific Publishing Company.},
	author_keywords = {Asymptotic-preserving methods; diffusion limit; discrete-velocity transport models; epidemic compartmental models; multiscale hyperbolic models; physics-informed neural networks},
	keywords = {Disease control; Hyperbolic functions; Learning systems; Asymptotic-preserving method; Asymptotics; Compartmental modelling; Diffusion limits; Discrete-velocity transport model; Epidemic compartmental model; Hyperbolic models; Multiscale hyperbolic model; Neural-networks; Physic-informed neural network; Transport modelling; Inverse problems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Green Open Access}
}

@ARTICLE{ning-etal:23-pinns-paralelas,
	author = {Ning, Xiao and Guan, Jinxing and Li, Xi-An and Wei, Yongyue and Chen, Feng},
	title = {Physics-Informed Neural Networks Integrating Compartmental Model for Analyzing COVID-19 Transmission Dynamics},
	year = {2023},
	journal = {Viruses},
	volume = {15},
	number = {8},
	doi = {10.3390/v15081749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168905930&doi=10.3390%2fv15081749&partnerID=40&md5=0d75aa500c625235ce5bda5a1fccedbc},
	abstract = {Modelling and predicting the behaviour of infectious diseases is essential for early warning and evaluating the most effective interventions to prevent significant harm. Compartmental models produce a system of ordinary differential equations (ODEs) that are renowned for simulating the transmission dynamics of infectious diseases. However, the parameters in compartmental models are often unknown, and they can even change over time in the real world, making them difficult to determine. This study proposes an advanced artificial intelligence approach based on physics-informed neural networks (PINNs) to estimate time-varying parameters from given data for the compartmental model. Our proposed PINNs method captures the complex dynamics of COVID-19 by integrating a modified Susceptible-Exposed-Infectious-Recovered-Death (SEIRD) compartmental model with deep neural networks. Specifically, we modelled the system of ODEs as one network and the time-varying parameters as another network to address significant unknown parameters and limited data. Such structure of the PINNs method is in line with the prior epidemiological correlations and comprises the mismatch between available data and network output and the residual of ODEs. The experimental findings on real-world reported data data have demonstrated that our method robustly and accurately learns the dynamics and forecasts future states. Moreover, as more data becomes available, our proposed PINNs method can be successfully extended to other regions and infectious diseases. © 2023 by the authors.},
	author_keywords = {compartmental models; COVID-19 transmission; forward-inverse problem; physics-informed neural networks},
	keywords = {Article; artificial neural network; compartment model; convolutional neural network; coronavirus disease 2019; deep neural network; effective reproduction number; forecasting; fully connected deep neural network; incubation time; mortality rate; physics informed neural network; recurrent neural network; residual network architecture; susceptible exposed infectious recovered death model; susceptible exposed infectious recovered model; virus transmission},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{yang-etal:25-dtpinns-paralelas,
	author = {Yang, Jie and Wang, Xuan and Lou, Jie},
	title = {COVID-19 REINFECTION PROCESSES: MATHEMATICAL MODELING, DATA FITTING WITH TIME-VARYING PARAMETERS, AND OPTIMAL CONTROL STUDIES},
	year = {2025},
	journal = {Journal of Biological Systems},
	volume = {33},
	number = {2},
	pages = {423 – 449},
	doi = {10.1142/S021833902550010X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212778806&doi=10.1142%2fS021833902550010X&partnerID=40&md5=0c66b2d85a85efc24d1997bdd2e3278a},
	abstract = {In this paper, we construct a COVID-19 dynamic model that included both the initial and reinfected population compartments, and conduct a structural identifiability analysis of the model parameters to ensure the robustness of the parameter fitting results. We use some actual statistical data from North Carolina to fit the model and estimate the values of some important parameters. In order to accurately fit the parameters in the model, we improve the physics-informed neural networks (PINNs) method in this paper, so that the fitting results can be reproduced on Matlab. The results of this study show that the transmission capacity of the virus in the reinfected person is only slightly lower than that of the first infected person, and vaccination is not effective in reducing the transmission rate of the virus. The death rate of the reinfected is much higher than that of the first infected person. Finally, we conduct a cost-effectiveness study using optimal control methods and found that, while it is easier to reduce reinfection by combining multiple strategies, the most effective strategy for reducing reinfection is to increase treatment cure rates and reduce direct or indirect contact among those who have recovered. © 2025 World Scientific Publishing Company.},
	author_keywords = {COVID-19; DTPINNs; Identifiability Analysis; Optimal Control; Parameter Estimation; Sensitivity Analysis},
	keywords = {SARS-CoV-2 vaccine; algorithm; Article; coronavirus disease 2019; cost effectiveness analysis; disease severity; human; infection control; infection rate; mathematical model; mortality rate; nerve cell network; North Carolina; pandemic; physics informed neural network; reinfection; sensitivity analysis; Severe acute respiratory syndrome coronavirus 2; time; vaccination; virus transmission},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{shaier-etal:22-dinns,
	author = {Shaier, Sagi and Raissi, Maziar and Seshaiyer, Padmanabhan},
	title = {Data-Driven Approaches for Predicting Spread of Infectious Diseases Through DINNs: Disease Informed Neural Networks},
	year = {2022},
	journal = {Letters in Biomathematics},
	volume = {9},
	number = {1},
	pages = {71 – 105},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136169389&partnerID=40&md5=2f5c407588258f3d630368da396af06a},
	abstract = {In this work, we present an approach called Disease Informed Neural Networks (DINNs) that can be employed to eectively predict the spread of infectious diseases. We build on the application of physics informed neural network (PINNs) to SIR compartmental models and expand it to a scaolded family of mathematical models describing various infectious diseases. We show how the neural networks are capable of learning how diseases spread, forecasting their progression, and nding their unique parameters (e.g., death rate). To demonstrate the robustness and ecacy of DINNs, we apply the approach to eleven highly infectious diseases that have been modeled in increasing levels of complexity. Our computational experiments suggest that DINNs is a reliable candidate to eectively learn the dynamics of their spread and forecast their progression into the future from available real-world data. Code and data can be found here: https://github.com/Shaier/DINN. © 2022, Intercollegiate Biomathematics Alliance. All rights reserved.},
	author_keywords = {Compartmental Models; Deep Learning; Epidemiology; Neural Networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@ARTICLE{madden-etal:24-time-series-sir,
	author = {Madden, Wyatt G. and Jin, Wei and Lopman, Benjamin and Zufle, Andreas and Dalziel, Benjamin and Metcalf, C.E. Jessica and Grenfell, Bryan T. and Lau, Max S.Y.},
	title = {Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models},
	year = {2024},
	journal = {PLoS Computational Biology},
	volume = {20},
	number = {11},
	doi = {10.1371/journal.pcbi.1012616},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209953346&doi=10.1371%2fjournal.pcbi.1012616&partnerID=40&md5=062a1370cac26e07e1443b565102f756},
	abstract = {Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that while the TSIR model yields similarly performant short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, our neural network model (SFNN) consistently achieves lower root mean squared error (RMSE) across other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental models and neural networks. Our results show that the TSIR can facilitate the reconstruction of latent susceptible dynamics, thereby enhancing both forecasts in terms of mean absolute error (MAE) and parameter inference of measles dynamics within the PINN. In summary, our results show that appropriately designed neural network-based models can outperform traditional mechanistic models for short to long-term forecasts, while simultaneously providing mechanistic interpretability. Our work also provides valuable insights into more effectively integrating machine learning models with mechanistic models to enhance public health responses to measles and similar infectious disease systems. © 2024 Madden et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Computational Biology; Disease Outbreaks; Endemic Diseases; England; Epidemiological Models; Forecasting; Humans; Measles; Neural Networks, Computer; Wales; Adversarial machine learning; Deep neural networks; Economic and social effects; Feedforward neural networks; Inference engines; Neural network models; Open access; Population dynamics; Systematic errors; Vortex flow; Comparative analyzes; Disease dynamics; Infectious disease; Machine learning models; Mechanistic models; Mechanistics; Neural network model; Neural-networks; Spatial features; Spatio-temporal; Article; artificial neural network; deep neural network; dynamics; endemic disease; forecasting; human; integration; machine learning; mathematical model; measles; mechanics; nerve cell network; nonlinear system; prediction; public health; root mean squared error; sea surface temperature; seasonal variation; sensitivity analysis; spatial analysis; vaccination; virus transmission; artificial neural network; bioinformatics; comparative study; England; epidemic; epidemiological model; epidemiology; procedures; Wales; Diseases},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{hu-etal:22-identificabilidade,
	author = {Hu, Haoran and Kennedy, Connor M. and Kevrekidis, Panayotis G. and Zhang, Hong-Kun},
	title = {A Modified PINN Approach for Identifiable Compartmental Models in Epidemiology with Application to COVID-19},
	year = {2022},
	journal = {Viruses},
	volume = {14},
	number = {11},
	doi = {10.3390/v14112464},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141594087&doi=10.3390%2fv14112464&partnerID=40&md5=a4e3585cc4da89e3d73b5a5303bdee78},
	abstract = {Many approaches using compartmental models have been used to study the COVID-19 pandemic, with machine learning methods applied to these models having particularly notable success. We consider the Susceptible–Infected–Confirmed–Recovered–Deceased (SICRD) compartmental model, with the goal of estimating the unknown infected compartment I, and several unknown parameters. We apply a variation of a “Physics Informed Neural Network” (PINN), which uses knowledge of the system to aid learning. First, we ensure estimation is possible by verifying the model’s identifiability. Then, we propose a wavelet transform to process data for the network training. Finally, our central result is a novel modification of the PINN’s loss function to reduce the number of simultaneously considered unknowns. We find that our modified network is capable of stable, efficient, and accurate estimation, while the unmodified network consistently yields incorrect values. The modified network is also shown to be efficient enough to be applied to a model with time-varying parameters. We present an application of our model results for ranking states by their estimated relative testing efficiency. Our findings suggest the effectiveness of our modified PINN network, especially in the case of multiple unknown variables. © 2022 by the authors.},
	author_keywords = {COVID-19; network dynamics; PINNs; wavelets},
	keywords = {COVID-19; Epidemiological Models; Humans; Neural Networks, Computer; Pandemics; Physics; algorithm; Article; artificial neural network; basic reproduction number; compartment model; epidemic; hospitalization; human; long short term memory network; loss of function mutation; machine learning; mathematical model; mathematical phenomena; physics; physics informed neural network; prevalence; recurrent disease; time series analysis; training; vaccination; wavelet analysis; wavelet transform; epidemiology; pandemic; physics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{li-etal:25-ordem-fracionaria,
	author = {Li, Ruqi and Song, Yurong and Li, Min and Qu, Hongbo and Jiang, Guo-Ping},
	title = {Dynamic analysis and data-driven inference of a fractional-order SEIHDR epidemic model with variable parameters},
	year = {2025},
	journal = {Mathematics and Computers in Simulation},
	volume = {230},
	pages = {1 – 19},
	doi = {10.1016/j.matcom.2024.10.042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208764841&doi=10.1016%2fj.matcom.2024.10.042&partnerID=40&md5=5df06da84bff8326ce9e8e000816f191},
	abstract = {To analyze and predict the evolution of contagion dynamics, fractional derivative modeling has emerged as an important technique. However, inferring the dynamical structure of fractional-order models with high degrees of freedom poses a challenge. In this paper, to elucidate the spreading mechanism and non-local properties of disease evolution, we propose a novel fractional-order SEIHDR epidemiological model with variable parameters, incorporating fractional derivatives in the Caputo sense. We compute the basic reproduction number by the next-generation matrix and establish local and global stability conditions based on this reproduction number. By using the fractional Adams–Bashforth method, we validate dynamical behaviors at different equilibrium points in both autonomous and non-autonomous scenarios, while qualitatively analyze the effects of fractional order on the dynamics. To effectively address the inverse problem of the proposed fractional SEIHDR model, we construct a fractional Physics-Informed Neural Network framework to simultaneously infer time-dependent parameters, fractional orders, and state components. Graphical results based on the COVID-19 pandemic data from Canada demonstrate the effectiveness of the proposed framework. © 2024 International Association for Mathematics and Computers in Simulation (IMACS)},
	author_keywords = {Caputo fractional derivative; Data-driven inference; Dynamic behavior; Epidemiological model; Physics-informed neural network},
	keywords = {Neural networks; Caputo fractional derivatives; Data driven; Data-driven inference; Dynamic behaviors; Dynamic data; Epidemiological modeling; Fractional order; Neural-networks; Physic-informed neural network; Variable-parameters; Inverse problems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{schiassi-etal:21-xtfc,
	author = {Schiassi, Enrico and De Florio, Mario and D’ambrosio, Andrea and Mortari, Daniele and Furfaro, Roberto},
	title = {Physics-informed neural networks and functional interpolation for data-driven parameters discovery of epidemiological compartmental models},
	year = {2021},
	journal = {Mathematics},
	volume = {9},
	number = {17},
	doi = {10.3390/math9172069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114263779&doi=10.3390%2fmath9172069&partnerID=40&md5=6d6d5add48f2d06e3d42ad56f2d97802},
	abstract = {In this work, we apply a novel and accurate Physics-Informed Neural Network Theory of Functional Connections (PINN-TFC) based framework, called Extreme Theory of Functional Connections (X-TFC), for data-physics-driven parameters’ discovery of problems modeled via Ordinary Differential Equations (ODEs). The proposed method merges the standard PINNs with a functional interpolation technique named Theory of Functional Connections (TFC). In particular, this work focuses on the capability of X-TFC in solving inverse problems to estimate the parameters govern-ing the epidemiological compartmental models via a deterministic approach. The epidemiological compartmental models treated in this work are Susceptible-Infectious-Recovered (SIR), Susceptible-Exposed-Infectious-Recovered (SEIR), and Susceptible-Exposed-Infectious-Recovered-Susceptible (SEIRS). The results show the low computational times, the high accuracy, and effectiveness of the X-TFC method in performing data-driven parameters’ discovery systems modeled via parametric ODEs using unperturbed and perturbed data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {COVID-19; Epidemiological compartmental models; Extreme learning machine; Functional interpolation; Physics-informed neural networks; Theory of functional connections},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Gold Open Access, Green Open Access}
}

@article{hornik:89-aprox-universais,
	title = {Multilayer feedforward networks are universal approximators},
	journal = {Neural Networks},
	volume = {2},
	number = {5},
	pages = {359-366},
	year = {1989},
	issn = {0893-6080},
	doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
	url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
	author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
	keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
	abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}

@article{grippen:03-aprox-universais-profundidade,
	title = {Approximation by neural networks with a bounded number of nodes at each level},
	journal = {Journal of Approximation Theory},
	volume = {122},
	number = {2},
	pages = {260-266},
	year = {2003},
	issn = {0021-9045},
	doi = {https://doi.org/10.1016/S0021-9045(03)00078-9},
	url = {https://www.sciencedirect.com/science/article/pii/S0021904503000789},
	author = {G. Gripenberg},
	keywords = {Approximation, Neural, Network, Multilayer},
	abstract = {It is shown that the general approximation property of feed-forward multilayer perceptron networks can be achieved in networks where the number of nodes in each layer is bounded, but the number of layers grows to infinity. This is the case provided the node function is twice continuously differentiable and not linear.}
}

@article{wengert:64-diferenciao-automatica,
	author = {Wengert, R. E.},
	title = {A simple automatic derivative evaluation program},
	year = {1964},
	issue_date = {Aug. 1964},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {7},
	number = {8},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/355586.364791},
	doi = {10.1145/355586.364791},
	abstract = {A procedure for automatic evaluation of total/partial derivatives of arbitrary algebraic functions is presented. The technique permits computation of numerical values of derivatives without developing analytical expressions for the derivatives. The key to the method is the decomposition of the given function, by introduction of intermediate variables, into a series of elementary functional steps. A library of elementary function subroutines is provided for the automatic evaluation and differentiation of these new variables. The final step in this process produces the desired function's derivative.The main feature of this approach is its simplicity. It can be used as a quick-reaction tool where the derivation of analytical derivatives is laborious and also as a debugging tool for programs which contain derivatives.},
	journal = {Commun. ACM},
	month = aug,
	pages = {463–464},
	numpages = {2}
}

@article{linnainmaa:76-diferenciao-automatica,
  author  = {Linnainmaa, Seppo},
  title   = {Taylor expansion of the accumulated rounding error},
  journal = {BIT Numerical Mathematics},
  year    = {1976},
  volume  = {16},
  number  = {2},
  pages   = {146--160},
  month   = jun,
  abstract= {The article describes analytic and algorithmic methods for determining the coefficients of the Taylor expansion of an accumulated rounding error with respect to the local rounding errors, and hence determining the influence of the local errors on the accumulated error. Second and higher order coefficients are also discussed, and some possible methods of reducing the extensive storage requirements are analyzed.},
  issn    = {1572-9125},
  doi     = {10.1007/BF01931367},
  url     = {https://doi.org/10.1007/BF01931367}
}

@inproceedings{pytorch:19,
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killea, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8024--8035},
  year={2019}
}

@article{tensorflow:16,
  author={Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man{\'e}, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Bennett and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi{\'e}gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  title={TensorFlow: A system for large-scale machine learning},
  journal={12th USENIX symposium on operating systems design and implementation (OSDI 16)},
  pages={265--283},
  year={2016}
}

@article{jin-et-al:21-navier-stokes,
    title = {NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations},
    journal = {Journal of Computational Physics},
    volume = {426},
    pages = {109951},
    year = {2021},
    issn = {0021-9991},
    doi = {https://doi.org/10.1016/j.jcp.2020.109951},
    url = {https://www.sciencedirect.com/science/article/pii/S0021999120307257},
    author = {Xiaowei Jin and Shengze Cai and Hui Li and George Em Karniadakis},
    keywords = {PINNs, Turbulence, Velocity-pressure formulation, Vorticity-velocity formulation, Ill-posed problems, Transfer learning}
}

@article{giampaolo-etal:22-gray-scott,
  TITLE = {{Physics-informed neural networks approach for 1D and 2D Gray-Scott systems}},
  AUTHOR = {Giampaolo, Fabio and de Rosa, Mariapia and Qi, Pian and Izzo, Stefano and Cuomo, Salvatore},
  URL = {https://hal.science/hal-04456081},
  JOURNAL = {{Advanced Modeling and Simulation in Engineering Sciences}},
  PUBLISHER = {{Springer}},
  SERIES = {Physics-Informed and Scientific Machine Learning Francesco Piccialli},
  VOLUME = {9},
  NUMBER = {1},
  PAGES = {1-17},
  YEAR = {2022},
  MONTH = May,
  DOI = {10.1186/s40323-022-00219-7},
  KEYWORDS = {Physics-Informed Neural Networks ; Scientific Machine Learning ; Gray-Scott systems ; Physics-Informed Neural Networks},
  PDF = {https://hal.science/hal-04456081v1/file/hal-04456081.pdf},
  HAL_ID = {hal-04456081},
  HAL_VERSION = {v1},
}

@InProceedings{guasti-santos:21,
	author="Guasti Junior, Wilson
	and Santos, Isaac P.",
	editor="Gervasi, Osvaldo
	and Murgante, Beniamino
	and Misra, Sanjay
	and Garau, Chiara
	and Ble{\v{c}}i{\'{c}}, Ivan
	and Taniar, David
	and Apduhan, Bernady O.
	and Rocha, Ana Maria A. C.
	and Tarantino, Eufemia
	and Torre, Carmelo Maria",
	title="Solving Differential Equations Using Feedforward Neural Networks",
	booktitle="Computational Science and Its Applications -- ICCSA 2021",
	year="2021",
	publisher="Springer International Publishing",
	address="Cham",
	pages="385--399",
	isbn="978-3-030-86973-1"
}

@article{yang:21-bpinns,
	title = {B-PINNs: Bayesian physics-informed neural networks for forward and inverse PDE problems with noisy data},
	journal = {Journal of Computational Physics},
	volume = {425},
	pages = {109913},
	year = {2021},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2020.109913},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120306872},
	author = {Liu Yang and Xuhui Meng and George Em Karniadakis},
	keywords = {Nonlinear PDEs, Noisy data, Bayesian physics-informed neural networks, Hamiltonian Monte Carlo, Variational inference},
	abstract = {We propose a Bayesian physics-informed neural network (B-PINN) to solve both forward and inverse nonlinear problems described by partial differential equations (PDEs) and noisy data. In this Bayesian framework, the Bayesian neural network (BNN) combined with a PINN for PDEs serves as the prior while the Hamiltonian Monte Carlo (HMC) or the variational inference (VI) could serve as an estimator of the posterior. B-PINNs make use of both physical laws and scattered noisy measurements to provide predictions and quantify the aleatoric uncertainty arising from the noisy data in the Bayesian framework. Compared with PINNs, in addition to uncertainty quantification, B-PINNs obtain more accurate predictions in scenarios with large noise due to their capability of avoiding overfitting. We conduct a systematic comparison between the two different approaches for the B-PINNs posterior estimation (i.e., HMC or VI), along with dropout used for quantifying uncertainty in deep neural networks. Our experiments show that HMC is more suitable than VI with mean field Gaussian approximation for the B-PINNs posterior estimation, while dropout employed in PINNs can hardly provide accurate predictions with reasonable uncertainty. Finally, we replace the BNN in the prior with a truncated Karhunen-Loève (KL) expansion combined with HMC or a deep normalizing flow (DNF) model as posterior estimators. The KL is as accurate as BNN and much faster but this framework cannot be easily extended to high-dimensional problems unlike the BNN based framework.}
}

@article{giles:77-sird,
  author  = {Giles, P.},
  title   = {The Mathematical Theory of Infectious Diseases and Its Applications},
  journal = {Journal of the Operational Research Society},
  year    = {1977},
  volume  = {28},
  number  = {2},
  pages   = {479--480},
  month   = jul,
  issn    = {1476-9360},
  doi     = {10.1057/jors.1977.92},
  url     = {https://doi.org/10.1057/jors.1977.92}
}

@article{shi-etal:24-convnet,
	title = {Physics-informed ConvNet: Learning physical field from a shallow neural network},
	journal = {Communications in Nonlinear Science and Numerical Simulation},
	volume = {132},
	pages = {107911},
	year = {2024},
	issn = {1007-5704},
	doi = {https://doi.org/10.1016/j.cnsns.2024.107911},
	url = {https://www.sciencedirect.com/science/article/pii/S1007570424000972},
	author = {Pengpeng Shi and Zhi Zeng and Tianshou Liang},
	keywords = {Physics-informed ConvNet(PICN), Machine learning, Data-driven scientific computing, Multi-frequency field, Operator estimating, Denoising display},
	abstract = {We introduce a novel methodology for solving nonlinear partial differential equation (PDE) on regular or irregular domains using physics-informed ConvNet, which we call the PICN. The network structure consists of three parts: 1) a convolutional neural network for physical field generation, 2) a pre-trained convolutional layer corresponding to the finite-difference filters to estimate differential fields of the generated physical field, and 3) an interpolation network for loss analysis in irregular geometry domains. From a CNN perspective, the physical field is generated by a deconvolution layer and a convolution layer. Unlike the standard Physics-informed Neural Network (PINN) approach, the convolutions corresponding to the finite-difference filters estimate the spatial gradients forming the physical operator and then construct the PDE residual in a PINN-like loss function. The total loss function involving boundary conditions and the physical constraints in irregular geometry domains can be calculated from an efficient linear interpolation network. The theoretical analysis of PICN convergence is performed on a simplified case for solving a one-dimensional physical field, and several examples of nonlinear PDE of solutions with multifrequency characteristics are executed. The theory and examples confirm the effective learning capability of PICN for the physical field solution with high-frequency components, compared to the standard PINN. A series of numerical cases are performed to validate the current PICN, including the solving (and estimation) of nonlinear physical operator equations and recovering physical information from noisy observations. First, the ability of PICN to solve nonlinear PDE has been verified by executing three nonlinear problems including ODE with sine nonlinearity, PDE involving nonlinear sine-square operators, and Schrödinger equation. The proposed PICN has been assessed by solving some nonlinear PDE on irregular domains such as star-shaped domain, bird-like domain, and starfish domain. Moreover, PICN is applied to identify the thermal diffusivity parameters in an anisotropic heat transfer problem from noisy data, and a denoising display of the temperature field from strong noisy data with standard deviations ranging from 0.1 to 0.4. The numerical results demonstrate the high accuracy approximation and fast convergence performance of PICN. The potential advantage in approximating complex physical field with multi-frequency components indicates that PICN may become an alternative efficient neural network solver in physics-informed machine learning. This paper is adapted from the work originally posted on arXiv.com by the same authors (arXiv:2201.10967, Jan 26, 2022). The data and code accompanying this paper are publicly available at https://github.com/zengzhi2015/PICN.}
}


@Article{schlickeiser-kroger:21-sirv,
	AUTHOR = {Schlickeiser, Reinhard and Kröger, Martin},
	TITLE = {Analytical Modeling of the Temporal Evolution of Epidemics Outbreaks Accounting for Vaccinations},
	JOURNAL = {Physics},
	VOLUME = {3},
	YEAR = {2021},
	NUMBER = {2},
	PAGES = {386--426},
	URL = {https://www.mdpi.com/2624-8174/3/2/28},
	ISSN = {2624-8174},
	ABSTRACT = {With the vaccination against Covid-19 now available, how vaccination campaigns influence the mathematical modeling of epidemics is quantitatively explored. In this paper, the standard susceptible-infectious-recovered/removed (SIR) epidemic model is extended to a fourth compartment, V, of vaccinated persons. This extension involves the time t-dependent effective vaccination rate, v(t), that regulates the relationship between susceptible and vaccinated persons. The rate v(t) competes with the usual infection, a(t), and recovery, μ(t), rates in determining the time evolution of epidemics. The occurrence of a pandemic outburst with rising rates of new infections requires k+b<1−2η, where k=μ(0)/a(0) and b=v(0)/a(0) denote the initial values for the ratios of the three rates, respectively, and η≪1 is the initial fraction of infected persons. Exact analytical inverse solutions t(Q) for all relevant quantities Q=[S,I,R,V] of the resulting SIRV model in terms of Lambert functions are derived for the semi-time case with time-independent ratios k and b between the recovery and vaccination rates to the infection rate, respectively. These inverse solutions can be approximated with high accuracy, yielding the explicit time-dependences Q(t) by inverting the Lambert functions. The values of the three parameters k, b and η completely determine the reduced time evolution of the SIRV-quantities Q(τ). The influence of vaccinations on the total cumulative number and the maximum rate of new infections in different countries is calculated by comparing with monitored real time Covid-19 data. The reduction in the final cumulative fraction of infected persons and in the maximum daily rate of new infections is quantitatively determined by using the actual pandemic parameters in different countries. Moreover, a new criterion is developed that decides on the occurrence of future Covid-19 waves in these countries. Apart from in Israel, this can happen in all countries considered.},
	DOI = {10.3390/physics3020028}
}

@article{bonfanti-etal:24-generalizacao-pinns,
  author  = {Bonfanti, Andrea and Santana, Roberto and Ellero, Marco and Gholami, Babak},
  title   = {On the generalization of {PINNs} outside the training domain and the hyperparameters influencing it},
  journal = {Neural Computing and Applications},
  year    = {2024},
  volume  = {36},
  number  = {36},
  pages   = {22677--22696},
  month   = dec,
  abstract= {Generalization is a key property of machine learning models to perform accurately on unseen data. Conversely, in the field of scientific machine learning (SciML), generalization entails not only predictive accuracy but also the capacity of the model to encapsulate underlying physical principles. In this paper, we delve into the concept of generalization for Physics-informed neural networks (PINNs) by investigating the consistency of the predictions of a PINN outside of its training domain. Through the lenses of a novel metric and statistical analysis, we study the scenarios in which a PINN can provide consistent predictions outside the region considered for training and hereinafter assess whether the algorithmic setup of the model can influence its potential for generalizing. Our results highlight why overparametrization is not a crucial component in SciML while encouraging overfitting on the training data. Despite being counterintuitive, the outcome of our analysis serves as a guideline for training PINNs for engineering applications.},
  issn    = {1433-3058},
  doi     = {10.1007/s00521-024-10178-2},
  url     = {https://doi.org/10.1007/s00521-024-10178-2}
}

@ARTICLE{scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@misc{opendatasus,
  author       = {Ministério da Saúde},
  title        = {Notificações de Síndrome Gripal - 2024},
  howpublished = {\url{https://opendatasus.saude.gov.br/dataset/notificacoes-de-sindrome-gripal-leve-2024}},
  year         = {2024},
  note         = {Accessed: 2025-09-07},
  url          = {https://opendatasus.saude.gov.br/dataset/notificacoes-de-sindrome-gripal-leve-2024}
}

@misc{flunet,
  author       = {World Health Organization},
  title        = {FluNet},
  howpublished = {\url{https://www.who.int/tools/flunet}},
  note         = {Accessed: 2025-09-07},
  url          = {https://www.who.int/tools/flunet}
}

@article{pang-etal:19-fractional-pinns,
author = {Pang, Guofei and Lu, Lu and Karniadakis, George Em},
title = {fPINNs: Fractional Physics-Informed Neural Networks},
journal = {SIAM Journal on Scientific Computing},
volume = {41},
number = {4},
pages = {A2603-A2626},
year = {2019},
doi = {10.1137/18M1229845},
URL = {https://doi.org/10.1137/18M1229845}
}

@inproceedings{jin-etal:2022-schrondiger,
	title={Physics-informed neural networks for quantum eigenvalue problems},
	author={Jin, Henry and Mattheakis, Marios and Protopapas, Pavlos},
	booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
	pages={1--8},
	year={2022},
	organization={IEEE}
}

@article{mcculloch-pitts:1943-perceptron,
	author    = {McCulloch, Warren S. and Pitts, Walter},
	title     = {A logical calculus of the ideas immanent in nervous activity},
	journal   = {The Bulletin of Mathematical Biophysics},
	year      = {1943},
	volume    = {5},
	number    = {4},
	pages     = {115--133},
	month     = dec,
	issn      = {1522-9602},
	doi       = {10.1007/BF02478259},
	url       = {https://doi.org/10.1007/BF02478259}
}

@article{chantada-etal:2023-cosmologia,
	title = {Cosmology-informed neural networks to solve the background dynamics of the Universe},
	author = {Chantada, Augusto T. and Landau, Susana J. and Protopapas, Pavlos and Sc\'occola, Claudia G. and Garraffo, Cecilia},
	journal = {Phys. Rev. D},
	volume = {107},
	issue = {6},
	pages = {063523},
	numpages = {28},
	year = {2023},
	month = {Mar},
	publisher = {American Physical Society},
	doi = {10.1103/PhysRevD.107.063523},
	url = {https://link.aps.org/doi/10.1103/PhysRevD.107.063523}
}

@inbook{kendall:2023-modelos-epd-estocasticos,
	url = {https://doi.org/10.1525/9780520350717-011},
	title = {DETERMINISTIC AND STOCHASTIC EPIDEMICS IN CLOSED POPULATIONS},
	booktitle = {Volume 4 Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, Volume IV},
	author = {David G. Kendall},
	editor = {Jerzy Neymann},
	publisher = {University of California Press},
	address = {Berkeley},
	pages = {149--166},
	doi = {doi:10.1525/9780520350717-011},
	isbn = {9780520350717},
	year = {2023},
	lastchecked = {2025-09-17}
}

@misc{liu-etal:2025-kans,
      title={KAN: Kolmogorov-Arnold Networks}, 
      author={Ziming Liu and Yixuan Wang and Sachin Vaidya and Fabian Ruehle and James Halverson and Marin Soljačić and Thomas Y. Hou and Max Tegmark},
      year={2025},
      eprint={2404.19756},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.19756}, 
}

@article{pang-etal:2019-fPINNs,
	author = {Pang, Guofei and Lu, Lu and Karniadakis, George Em},
	title = {fPINNs: Fractional Physics-Informed Neural Networks},
	journal = {SIAM Journal on Scientific Computing},
	volume = {41},
	number = {4},
	pages = {A2603-A2626},
	year = {2019},
	doi = {10.1137/18M1229845},
	URL = {https://doi.org/10.1137/18M1229845},
	eprint = {https://doi.org/10.1137/18M1229845}
}

@article{sirignano-spiliopoulos:2018-deepgalerkin,
	title = {DGM: A deep learning algorithm for solving partial differential equations},
	journal = {Journal of Computational Physics},
	volume = {375},
	pages = {1339-1364},
	year = {2018},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2018.08.029},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999118305527},
	author = {Justin Sirignano and Konstantinos Spiliopoulos},
	keywords = {Partial differential equations, Machine learning, Deep learning, High-dimensional partial differential equations},
}

@article{jacquez:1988-modelagam-hiv-matriz,
	title = {Modeling and analyzing HIV transmission: the effect of contact patterns},
	journal = {Mathematical Biosciences},
	volume = {92},
	number = {2},
	pages = {119-199},
	year = {1988},
	issn = {0025-5564},
	doi = {https://doi.org/10.1016/0025-5564(88)90031-4},
	url = {https://www.sciencedirect.com/science/article/pii/0025556488900314},
	author = {John A. Jacquez and Carl P. Simon and James Koopman and Lisa Sattenspiel and Timothy Perry},
}

@article{noble:1974-sir-difusao,
  author    = {Noble, J. V.},
  title     = {Geographic and temporal development of plagues},
  journal   = {Nature},
  year      = {1974},
  volume    = {250},
  number    = {5469},
  pages     = {726--729},
  month     = aug,
  abstract  = {ALTHOUGH deterministic and stochastic descriptions of localised epidemics abound in the literature of epidemiology and quantitative biology1,2, the geographic spread of epidemics has not been analyzed in such detail. (Although in ref. 2, page 205, Bailey gives equations similar in spirit to my equation (1) they seem to lack physical significance.) Realistic mathematical models of the geotemporal development of plagues could be useful in the study of epizootics (that is, in ecology, wildlife management or veterinary medicine), of social phenomena (such as the spread of drug abuse or fads), and of history. Needless to say, such models should also be applicable to public health questions.},
  issn      = {1476-4687},
  doi       = {10.1038/250726a0},
  url       = {https://doi.org/10.1038/250726a0}
}

@article{tamerius-etal:2013-fatores-influenza,
    doi = {10.1371/journal.ppat.1003194},
    author = {Tamerius, James D. AND Shaman, Jeffrey AND Alonso, Wladmir J. AND Bloom-Feshbach, Kimberly AND Uejio, Christopher K. AND Comrie, Andrew AND Viboud, Cécile},
    journal = {PLOS Pathogens},
    publisher = {Public Library of Science},
    title = {Environmental Predictors of Seasonal Influenza Epidemics across Temperate and Tropical Climates},
    year = {2013},
    month = {03},
    volume = {9},
    url = {https://doi.org/10.1371/journal.ppat.1003194},
    pages = {1-12},
    number = {3},
}

@article{nascimento-etal:2020-DA-e-pinns-odes,
	title = {A tutorial on solving ordinary differential equations using Python and hybrid physics-informed neural network},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {96},
	pages = {103996},
	year = {2020},
	issn = {0952-1976},
	doi = {https://doi.org/10.1016/j.engappai.2020.103996},
	url = {https://www.sciencedirect.com/science/article/pii/S095219762030292X},
	author = {Renato G. Nascimento and Kajetan Fricke and Felipe A.C. Viana},
	keywords = {Physics-informed neural network, Scientific machine learning, Uncertainty quantification, Hybrid model python implementation},
}

@article{zhang-etal:2020-stochastic-pde-pinns,
	author = {Zhang, Dongkun and Guo, Ling and Karniadakis, George Em},
	title = {Learning in Modal Space: Solving Time-Dependent Stochastic PDEs Using Physics-Informed Neural Networks},
	journal = {SIAM Journal on Scientific Computing},
	volume = {42},
	number = {2},
	pages = {A639-A665},
	year = {2020},
	doi = {10.1137/19M1260141},
	URL = {https://doi.org/10.1137/19M1260141},
	eprint = {https://doi.org/10.1137/19M1260141}
}

@article{jagtap-etal:2020-convervative-pinns,
	title = {Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	volume = {365},
	pages = {113028},
	year = {2020},
	issn = {0045-7825},
	doi = {https://doi.org/10.1016/j.cma.2020.113028},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782520302127},
	author = {Ameya D. Jagtap and Ehsan Kharazmi and George Em Karniadakis},
	keywords = {cPINN, Mortar PINN, Domain decomposition, Machine learning, Conservation laws, Inverse problems},
	abstract = {We propose a conservative physics-informed neural network (cPINN) on discrete domains for nonlinear conservation laws. Here, the term discrete domain represents the discrete sub-domains obtained after division of the computational domain, where PINN is applied and the conservation property of cPINN is obtained by enforcing the flux continuity in the strong form along the sub-domain interfaces. In case of hyperbolic conservation laws, the convective flux contributes at the interfaces, whereas in case of viscous conservation laws, both convective and diffusive fluxes contribute. Apart from the flux continuity condition, an average solution (given by two different neural networks) is also enforced at the common interface between two sub-domains. One can also employ a deep neural network in the domain, where the solution may have complex structure, whereas a shallow neural network can be used in the sub-domains with relatively simple and smooth solutions. Another advantage of the proposed method is the additional freedom it gives in terms of the choice of optimization algorithm and the various training parameters like residual points, activation function, width and depth of the network etc. Various forms of errors involved in cPINN such as optimization, generalization and approximation errors and their sources are discussed briefly. In cPINN, locally adaptive activation functions are used, hence training the model faster compared to its fixed counterparts. Both, forward and inverse problems are solved using the proposed method. Various test cases ranging from scalar nonlinear conservation laws like Burgers, Korteweg–de Vries (KdV) equations to systems of conservation laws, like compressible Euler equations are solved. The lid-driven cavity test case governed by incompressible Navier–Stokes equation is also solved and the results are compared against a benchmark solution. The proposed method enjoys the property of domain decomposition with separate neural networks in each sub-domain, and it efficiently lends itself to parallelized computation, where each sub-domain can be assigned to a different computational node.}
}

@article{jagtap-etal:2020-extended-pinns,
	title={Extended physics-informed neural networks (xpinns): A generalized space-time domain decomposition based deep learning framework for nonlinear partial differential equations},
	author={Jagtap, Ameya D and Karniadakis, George Em},
	journal={Communications in Computational Physics},
	volume={28},
	number={5},
	pages={2002--2041},
	year={2020}
}

@article{hu-etal:2023-augmented-pinns,
	title = {Augmented Physics-Informed Neural Networks (APINNs): A gating network-based soft domain decomposition methodology},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {126},
	pages = {107183},
	year = {2023},
	issn = {0952-1976},
	doi = {https://doi.org/10.1016/j.engappai.2023.107183},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197623013672},
	author = {Zheyuan Hu and Ameya D. Jagtap and George Em Karniadakis and Kenji Kawaguchi},
	keywords = {Physics-informed neural network, Extended physics-informed neural network, Domain decomposition, Gating networks},
}

@article{dwivedi:2019-distributed-pinns,
	title={Distributed physics informed neural network for data-efficient solution to partial differential equations},
	author={Vikas Dwivedi and Nishant Parashar and Balaji Srinivasan},
	journal={ArXiv},
	year={2019},
	volume={abs/1907.08967},
	url={https://api.semanticscholar.org/CorpusID:198147990}
}

@article{fugh-etal:2022-fuzzy-pinns,
	title = {Interval and fuzzy physics-informed neural networks for uncertain fields},
	journal = {Probabilistic Engineering Mechanics},
	volume = {68},
	pages = {103240},
	year = {2022},
	issn = {0266-8920},
	doi = {https://doi.org/10.1016/j.probengmech.2022.103240},
	url = {https://www.sciencedirect.com/science/article/pii/S0266892022000273},
	author = {Jan N. Fuhg and Ioannis Kalogeris and Amélie Fau and Nikolaos Bouklas},
	keywords = {Physics-informed machine learning, Fuzzy set theory, Interval set theory, Non-probabilistic uncertainty},
	abstract = {Temporally and spatially dependent uncertain parameters are regularly encountered in engineering applications. Commonly these uncertainties are accounted for using random fields and processes, which require knowledge about the appearing probability distributions functions that is not readily available. In these cases non-probabilistic approaches such as interval analysis and fuzzy set theory are helpful to analyze uncertainty. Partial differential equations involving fuzzy and interval fields are traditionally solved using the finite element method where the input fields are sampled using some basis function expansion methods. This approach however relies on information about the spatial correlation of the fields, which is not always obtainable. In this work we utilize physics-informed neural networks (PINNs) to solve interval and fuzzy partial differential equations. The resulting network structures termed interval physics-informed neural networks (iPINNs) and fuzzy physics-informed neural networks (fPINNs) show promising results for obtaining bounded solutions of equations involving spatially and/or temporally uncertain parameter fields. In contrast to finite element approaches, no correlation length specification of the input fields as well as no Monte-Carlo simulations are necessary. In fact, information about the input interval fields is obtained directly as a byproduct of the presented solution scheme. Furthermore, all major advantages of PINNs are retained, i.e. meshfree nature of the scheme, and ease of inverse problem set-up.}
}

@article{mohammadian-etal:2023-gradient-enhanced,
	title = {Gradient-enhanced physics-informed neural networks for power systems operational support},
	journal = {Electric Power Systems Research},
	volume = {223},
	pages = {109551},
	year = {2023},
	issn = {0378-7796},
	doi = {https://doi.org/10.1016/j.epsr.2023.109551},
	url = {https://www.sciencedirect.com/science/article/pii/S0378779623004406},
	author = {Mostafa Mohammadian and Kyri Baker and Ferdinando Fioretto},
	keywords = {Deep learning, Power system dynamics, Physics-informed neural networks, Optimal power flow, Transfer learning},
}

@article{ren-etal:2022-phycrnet,
	title = {PhyCRNet: Physics-informed convolutional-recurrent network for solving spatiotemporal PDEs},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	volume = {389},
	pages = {114399},
	year = {2022},
	issn = {0045-7825},
	doi = {https://doi.org/10.1016/j.cma.2021.114399},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782521006514},
	author = {Pu Ren and Chengping Rao and Yang Liu and Jian-Xun Wang and Hao Sun},
	keywords = {Convolutional-recurrent learning, Partial differential equations, Encoder–decoder, Physics-informed deep learning, Residual connection, Hard-encoding of I/BCs},
}

@article{pakravan-et:2021-bipde,
	title = {Solving inverse-PDE problems with physics-aware neural networks},
	journal = {Journal of Computational Physics},
	volume = {440},
	pages = {110414},
	year = {2021},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2021.110414},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121003090},
	author = {Samira Pakravan and Pouria {A. Mistani} and Miguel A. Aragon-Calvo and Frederic Gibou},
	keywords = {Inverse problems, Differential equations, Deep learning, Scientific machine learning, Numerical methods},
}

@inproceedings{benjamin-etal:2022-rnn-dct-networks,
	author="Wu, Benjamin
	and Hennigh, Oliver
	and Kautz, Jan
	and Choudhry, Sanjay
	and Byeon, Wonmin",
	editor="Groen, Derek
	and de Mulatier, Cl{\'e}lia
	and Paszynski, Maciej
	and Krzhizhanovskaya, Valeria V.
	and Dongarra, Jack J.
	and Sloot, Peter M. A.",
	title="Physics Informed RNN-DCT Networks for Time-Dependent Partial Differential Equations",
	booktitle="Computational Science -- ICCS 2022",
	year="2022",
	publisher="Springer International Publishing",
	address="Cham",
	pages="372--379",
	isbn="978-3-031-08754-7"
}

@inproceedings{han-etal:2023-hierarchical-learning,
	author="Han, Jihun
	and Lee, Yoonsang",
	editor="Miky{\v{s}}ka, Ji{\v{r}}{\'i}
	and de Mulatier, Cl{\'e}lia
	and Paszynski, Maciej
	and Krzhizhanovskaya, Valeria V.
	and Dongarra, Jack J.
	and Sloot, Peter M.A.",
	title="Hierarchical Learning to Solve PDEs Using Physics-Informed Neural Networks",
	booktitle="Computational Science -- ICCS 2023",
	year="2023",
	publisher="Springer Nature Switzerland",
	address="Cham",
	pages="548--562",
	abstract="The neural network-based approach to solving partial differential equations has attracted considerable attention. In training a neural network, the network learns global features corresponding to low-frequency components while high-frequency components are approximated at a much slower rate. For a class of equations in which the solution contains a wide range of scales, the network training process can suffer from slow convergence and low accuracy due to its inability to capture the high-frequency components. In this work, we propose a sequential training based on a hierarchy of networks to improve the convergence rate and accuracy of the neural network solution to partial differential equations. The proposed method comprises multi-training levels in which a newly introduced neural network is guided to learn the residual of the previous level approximation. We validate the efficiency and robustness of the proposed hierarchical approach through a suite of partial differential equations.",
	isbn="978-3-031-36024-4"
}

@article{edlnd-etal:2011-sugestao-beta-t,
	title = {Comparing three basic models for seasonal influenza},
	journal = {Epidemics},
	volume = {3},
	number = {3},
	pages = {135-142},
	year = {2011},
	issn = {1755-4365},
	doi = {https://doi.org/10.1016/j.epidem.2011.04.002},
	url = {https://www.sciencedirect.com/science/article/pii/S1755436511000259},
	author = {Stefan Edlund and James Kaufman and Justin Lessler and Judith Douglas and Michal Bromberg and Zalman Kaufman and Ravit Bassal and Gabriel Chodick and Rachel Marom and Varda Shalev and Yossi Mesika and Roni Ram and Alex Leventhal},
	keywords = {Simulation, Compartmental disease models, Predictive validity, Epidemics},
}

@article{andreu-vilarroig-etal:2025-sugestao-beta-t,
  author    = {Andreu-Vilarroig, Carlos and Gonz{\'a}lez-Parra, Gilberto and Villanueva, Rafael-Jacinto},
  title     = {Mathematical Modeling of Influenza Dynamics: Integrating Seasonality and Gradual Waning Immunity},
  journal   = {Bulletin of Mathematical Biology},
  year      = {2025},
  volume    = {87},
  number    = {6},
  pages     = {75},
  month     = may,
  issn      = {1522-9602},
  doi       = {10.1007/s11538-025-01454-w},
  url       = {https://doi.org/10.1007/s11538-025-01454-w}
}

@article{wheatcraft-2008-conservacao-de-massa-fracionaria,
	title = {Fractional conservation of mass},
	journal = {Advances in Water Resources},
	volume = {31},
	number = {10},
	pages = {1377-1381},
	year = {2008},
	issn = {0309-1708},
	doi = {https://doi.org/10.1016/j.advwatres.2008.07.004},
	url = {https://www.sciencedirect.com/science/article/pii/S0309170808001188},
	author = {Stephen W. Wheatcraft and Mark M. Meerschaert},
	keywords = {Fractional derivative, Fractional Taylor series, Conservation of mass},
}

@article{atangana-2013-fluxo-ordem-fracionaria,
	author = {Atangana, Abdon and Bildik, Necdet},
	title = {The Use of Fractional Order Derivative to Predict the Groundwater Flow},
	journal = {Mathematical Problems in Engineering},
	volume = {2013},
	number = {1},
	pages = {543026},
	doi = {https://doi.org/10.1155/2013/543026},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2013/543026},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1155/2013/543026},
	abstract = {The aim of this work was to convert the Thiem and the Theis groundwater flow equation to the time-fractional groundwater flow model. We first derived the analytical solution of the Theim time-fractional groundwater flow equation in terms of the generalized Wright function. We presented some properties of the Laplace-Carson transform. We derived the analytical solution of the Theis-time-fractional groundwater flow equation (TFGFE) via the Laplace-Carson transform method. We introduced the generalized exponential integral, as solution of the TFGFE. This solution is in perfect agreement with the data observed from the pumping test performed by the Institute for Groundwater Study on one of its borehole settled on the test site of the University of the Free State. The test consisted of the pumping of the borehole at the constant discharge rate Q and monitoring the piezometric head for 350 minutes.},
	year = {2013}
}

@misc{karlbauer-2022-finns,
      title={Composing Partial Differential Equations with Physics-Aware Neural Networks}, 
      author={Matthias Karlbauer and Timothy Praditia and Sebastian Otte and Sergey Oladyshkin and Wolfgang Nowak and Martin V. Butz},
      year={2022},
      eprint={2111.11798},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2111.11798}, 
}


@article{sun-e-feng:2023-gPINNs,
	AUTHOR = {Sun, Kuo and Feng, Xinlong},
	TITLE = {A Second-Order Network Structure Based on Gradient-Enhanced Physics-Informed Neural Networks for Solving Parabolic Partial Differential Equations},
	JOURNAL = {Entropy},
	VOLUME = {25},
	YEAR = {2023},
	NUMBER = {4},
	ARTICLE-NUMBER = {674},
	URL = {https://www.mdpi.com/1099-4300/25/4/674},
	PubMedID = {37190465},
	ISSN = {1099-4300},
	ABSTRACT = {Physics-informed neural networks (PINNs) are effective for solving partial differential equations (PDEs). This method of embedding partial differential equations and their initial boundary conditions into the loss functions of neural networks has successfully solved forward and inverse PDE problems. In this study, we considered a parametric light wave equation, discretized it using the central difference, and, through this difference scheme, constructed a new neural network structure named the second-order neural network structure. Additionally, we used the adaptive activation function strategy and gradient-enhanced strategy to improve the performance of the neural network and used the deep mixed residual method (MIM) to reduce the high computational cost caused by the enhanced gradient. At the end of this paper, we give some numerical examples of nonlinear parabolic partial differential equations to verify the effectiveness of the method.},
	DOI = {10.3390/e25040674}
}



